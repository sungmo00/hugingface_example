{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "PYP9e1DtWHer",
      "metadata": {
        "id": "PYP9e1DtWHer",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "GCwKSrL0WAaY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCwKSrL0WAaY",
        "outputId": "6ebaeffd-0362-4dc7-95bb-554933edec4d",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==2.20.0\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting evaluate==0.4.0\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting scikit-learn==1.4.2\n",
            "  Downloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (17.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.20.0)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.20.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (4.67.1)\n",
            "Collecting xxhash (from datasets==2.20.0)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.20.0)\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets==2.20.0)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (6.0.2)\n",
            "Collecting responses<0.19 (from evaluate==0.4.0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.2->datasets==2.20.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2024.12.14)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.20.0)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.20.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.20.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.20.0) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.20.0) (1.17.0)\n",
            "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow-hotfix, fsspec, dill, scikit-learn, responses, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.5.0 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 evaluate-0.4.0 fsspec-2024.5.0 multiprocess-0.70.16 pyarrow-hotfix-0.6 responses-0.18.0 scikit-learn-1.4.2 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# 적용 후 런타임 > 세션 다시 시작\n",
        "!pip install -U \\\n",
        "     datasets==2.20.0 \\\n",
        "     evaluate==0.4.0 \\\n",
        "     scikit-learn==1.4.2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bmsQwngTWLJz",
      "metadata": {
        "id": "bmsQwngTWLJz"
      },
      "source": [
        "# 5.3.2 Causal LM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g0p0jKafWVcI",
      "metadata": {
        "id": "g0p0jKafWVcI"
      },
      "source": [
        "### 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ea352356-1085-4c09-a441-91d9aef6f7e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730,
          "referenced_widgets": [
            "f8149f84aaf34582b80e8023bb67b980",
            "4afa1714d07b4151906202c82228a8e4",
            "0a84bf8516da4ea39240d80ecd2a2d38",
            "3b6724c3b869411a8c976e93170ca342",
            "573ab8b10ef64b92bca7a1ecf9942751",
            "0d7b1889911e473691c15b9bc1ec2d3a",
            "eda16e488446459e84f12cabd0030924",
            "59603c14d2b64238a584c7d1c72b7dcd",
            "98f0872304d046c185d74540be168dec",
            "4e3e945b2c5c459e8856f3c918f47cfa",
            "586e973275724812b06d58d24ce56735",
            "c3f1dff943594298a597759541eab7e7",
            "f6b12e01b7d14c9d9fbdf11b735d7b46",
            "544ed9842d1e45379b2d3b733ad14794",
            "17b5c02be59c4417844e66a8771acebb",
            "2e78436081aa43e598b36dcd76457dc8",
            "7179e1c8059d4f328b336becf961dfad",
            "fa674bb9f1c24269a24f28ddeef0f1cd",
            "e71fcb632f664a5eb0f3f429342a910e",
            "6e988c87a379480f8119fb456e30f746",
            "871c4f9e24c640d395a9b01fb23421aa",
            "dcbd7f77ead4495abe216efca288c970",
            "e8b066510d824d97886dce4cc2c852dc",
            "7c9a0ecf0ff64d669616667ec858e1e3",
            "a96bc98aecd74a1db7e7220d51e29ace",
            "7d31fac6ca264c19afb99625b84f39d0",
            "7e4b6a90d7b14255ac0b3521b73f82b8",
            "6bad507345ee4124a9570c020d43734b",
            "a39c9d962eb7481ca6545b9ae8dc7b61",
            "ab86c34f5f894e4f8f4fea04728b726a",
            "e45de1d31c4c4587a270a7f33f1d2ec6",
            "d83dff4d5b884b3d8cbbfb2ea991873c",
            "8b6781fb51a6460988d08489535c3d8b"
          ]
        },
        "id": "ea352356-1085-4c09-a441-91d9aef6f7e0",
        "outputId": "aed8d6aa-cb96-44d9-e6a4-c32df13284af",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8149f84aaf34582b80e8023bb67b980"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3f1dff943594298a597759541eab7e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8b066510d824d97886dce4cc2c852dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51200, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2SdpaAttention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "\n",
        "model_name = \"skt/kogpt2-base-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    bos_token=\"</s>\",\n",
        "    eos_token=\"</s>\",\n",
        "    unk_token=\"<unk>\",\n",
        "    pad_token=\"<pad>\",\n",
        "    mask_token=\"<mask>\"\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7jNydvUgMJ4",
      "metadata": {
        "id": "b7jNydvUgMJ4"
      },
      "source": [
        "### 데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ca777a94-7187-4f6e-beb1-730f7601ce87",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "f224b7171d1640f7b6cb09c74033cd51",
            "6a2fbf152cee4b37b3e0d33d4f37766c",
            "4ebfe74330874d3d8cafae67bb2bb217",
            "48c809e94e63475e8156f4e89579958f",
            "4b7bae6d16ca45d3b45686a38b53181a",
            "e947b5f0ef214a52ba427f01e7cd4565",
            "6cf9098745054e81b9210a8dd02ea5c6",
            "c0abc90d475d422181f86dcc6caf35d9",
            "ed7e83b0eb644c2ab610aee56c28f7b7",
            "e139325ef0c441b292c60d705ceb57dc",
            "bd4ee7307af14cbfae76dd91fb619ba6",
            "c8516b1405544dcd928d4c9471221530",
            "13a2de01fa1a4de0bd4f1649d4517c8d",
            "9ada10b162874771876582067d39df77",
            "28ad72ee3b074f97b3d74b7b5c5b5bcc",
            "7f1f1d29fb56451b9ac6245bc39e596a",
            "3fee8a8f61874745ac72dffb8219ee95",
            "dc581353cb194ca3be57353cc7dfd239",
            "af5b980309a34688a2a83e3d49732183",
            "cca18bfb4aac4fc19a296c2d9a59d688",
            "86f6677f950d4129834c46a2bfa1f764",
            "a836fd66e9cc4b60be9ec4338f375896",
            "4a2ac85ebf4941dab423228ad91372e1",
            "ab85c241e551429a9b15a31f85627650",
            "3ab8ec46d6ca40bf8026ec14b1fa0728",
            "cd4d3a3a83da4d1d9f4956e42df4c4ba",
            "98a9026ec054459fae7f063d0fcfc903",
            "a46240b04e6d439596591c1981d25f0a",
            "ebf0a0564e214e0a8b77a36f883de869",
            "a1e51a0474e948bebaa7feb6c3d14d72",
            "a623c40b07ba426b9ca8dad98116e613",
            "fc54e099b57d4dbf879b3dd30755741d",
            "4fe8cd89598b4f349c2996d839e74735",
            "0d4ea6002a274a46987142bf8862da18",
            "76c3728f537445d3aac23f5958be5ab2",
            "122262b1241d410aad9c4e708345e520",
            "2c50885e727844b797bf97c2d2e89286",
            "1c3e9979026645df8110b708a89cc3f7",
            "89ce60289abe42098049ab811854a37e",
            "d440100143c143bdb80fd76a2e16fa80",
            "fed8428f5fdc4a3cb6b049f87acdf7d2",
            "fbc4583d551e4f419f57acb89b0ad520",
            "0e81221f40bd48aba70714f8c7c75f4f",
            "b01582547c6d4cf6806bd89f1d263b40"
          ]
        },
        "id": "ca777a94-7187-4f6e-beb1-730f7601ce87",
        "outputId": "720d344d-cfe5-4b47-8898-6bb9438df5ce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.70k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f224b7171d1640f7b6cb09c74033cd51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/1.04k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8516b1405544dcd928d4c9471221530"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for heegyu/kowikitext contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/heegyu/kowikitext.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/498M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a2ac85ebf4941dab423228ad91372e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d4ea6002a274a46987142bf8862da18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'revid', 'url', 'title', 'text'],\n",
              "        num_rows: 8000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'revid', 'url', 'title', 'text'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "split_dict = {\n",
        "    \"train\": \"train[:8000]\",\n",
        "    \"test\": \"train[8000:10000]\",\n",
        "    \"unused\": \"train[10000:]\",\n",
        "}\n",
        "dataset = load_dataset(\"heegyu/kowikitext\", split=split_dict)\n",
        "del dataset[\"unused\"]\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c799c11a-2caf-4495-84d5-d426bb8116d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268,
          "referenced_widgets": [
            "6158d34861e3412c8969c1be9fc2208e",
            "9c12ca9bfa414df4b49351d506a8b7e6",
            "9c5fb54d607b4934a7cc37390814ae3e",
            "fc00459b254647a79bb18885b8f2b591",
            "797a95d252444e5292114d47d7e59453",
            "053bcbaf9a3945f1b8aebef5034691c2",
            "79d4ae117d5244b2b8cd2eedc9587c32",
            "73676e1640a44e9c9ed8d75d6f72a087",
            "cc06fd03bdea4ad9a5f5f10d635e7827",
            "ad7bb53d121640e484866ea7a36a2c18",
            "29656ca237be44edb1f0f38f80e8507a",
            "09524b9fd01e41ba81bf8ddb4fb0d320",
            "2a277bf9de4840eaaea89fc7ea6933a5",
            "a8d81d22136145e786d258fd991d6ca0",
            "55c665b92bc64a369a75d48d02255c20",
            "e17e6ec2f924499190efcd5d37b6f9cb",
            "c71aef4be6e54c9795f15644f3b84ef4",
            "de5ccbf1bf574cd0aa22c60382ce1b77",
            "dc7904204b4b49ec8d50a1d7d000857d",
            "f65aa090902b49128b0069e8de6b6cca",
            "23e8490f4f5e41e892216ba974732a7c",
            "ee7e7a14aeae47eaa6d3d6194f5c7d32"
          ]
        },
        "id": "c799c11a-2caf-4495-84d5-d426bb8116d2",
        "outputId": "b8808585-2c02-4c26-9b62-6d342914b682"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/8000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6158d34861e3412c8969c1be9fc2208e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09524b9fd01e41ba81bf8ddb4fb0d320"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask'],\n",
              "        num_rows: 8000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "tokenized_dataset = dataset.map(\n",
        "    lambda batch: tokenizer([f\"{ti}\\n{te}\" for ti, te in zip(batch[\"title\"], batch[\"text\"])]),\n",
        "    batched=True,\n",
        "    num_proc=2,\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        ")\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5fb8bcb2-26e9-41f5-9b22-3fd30b49f006",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287,
          "referenced_widgets": [
            "3d73214f90f84e05a9aedf82f55194c0",
            "9e5933c3492f4022b69ef160f99cc246",
            "fe31b536155543b8aaa65de7067ba374",
            "885b9e4ba61c4e6da32c29609897a6e5",
            "258111d6a0324bc5b75c74e58eb0eb05",
            "75d74e494e1c49a283a21bfdfb648272",
            "cd83babb7e134adf8d08888d1bf40fec",
            "f764c70c821149149cd3690b817e6fcc",
            "93c28c01c9ee4d4cbdabfba33b424aed",
            "7432e25d95334748a7cc81eec47b5c87",
            "779e89edcf564242a510f3359e849b3b",
            "b0a702148c0148779562417d4bff0a14",
            "5e084432777a4b1290437ef51c35cbc1",
            "0ea0372581cc4c1198f727b347d171a7",
            "ba741184bc36420284f0b7cb7c69760d",
            "0deb5530fd634c14a1835204b455bf2a",
            "8fbc56f1e6704d9fa42a899a6d718e13",
            "c405b37688f84d60bd77c0770cb5614a",
            "8c1896e6fa0d456ebfef38e67c334d73",
            "1e62f5165a154636be60648f5e530b19",
            "fb71bdeb4676441aa0cb6e7f2de31d5a",
            "41e5224ea53247d4a1f0c6a08b04a37a"
          ]
        },
        "id": "5fb8bcb2-26e9-41f5-9b22-3fd30b49f006",
        "outputId": "234c3def-bd55-4e60-a972-e52925e3ec6f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/8000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d73214f90f84e05a9aedf82f55194c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0a702148c0148779562417d4bff0a14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask'],\n",
            "        num_rows: 18365\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'attention_mask'],\n",
            "        num_rows: 2400\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "max_length = 512\n",
        "def group_texts(batched_sample):\n",
        "    sample = {k: v[0] for k, v in batched_sample.items()}\n",
        "\n",
        "    if sample[\"input_ids\"][-1] != tokenizer.eos_token_id:\n",
        "        for k in sample.keys():\n",
        "            sample[k].append(\n",
        "                tokenizer.eos_token_id if k == \"input_ids\" else sample[k][-1]\n",
        "            )\n",
        "\n",
        "    result = {k: [v[i: i + max_length] for i in range(0, len(v), max_length)] for k, v in sample.items()}\n",
        "    return result\n",
        "\n",
        "grouped_dataset = tokenized_dataset.map(\n",
        "    group_texts,\n",
        "    batched=True,\n",
        "    batch_size=1,\n",
        "    num_proc=2,\n",
        ")\n",
        "print(len(grouped_dataset[\"train\"][0][\"input_ids\"]))\n",
        "print(grouped_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "37fc1c78-360d-4e7e-9f6b-67250eb7a743",
      "metadata": {
        "id": "37fc1c78-360d-4e7e-9f6b-67250eb7a743"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "sample = collator([grouped_dataset[\"train\"][i] for i in range(1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "247bd106-3aef-4fd9-bd1d-4c60fc1e649b",
      "metadata": {
        "id": "247bd106-3aef-4fd9-bd1d-4c60fc1e649b"
      },
      "source": [
        "### 문장 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ykAGXChhW06l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykAGXChhW06l",
        "outputId": "dc80cfea-27dd-4d43-a960-680bf0c4661e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "지난해 7월, 롯데백화점 본점 지하 1층 식품매장에서 판매된 '롯데 햄버거' 제품에서 대장균이 검출돼 판매 중단된 바 있다.\n",
            "롯데백화점 측은 \"햄버거 판매 중단은 롯데백화점 본점 식품매장의 위생과 안전관리에 대한 고객들의 신뢰가 크게 훼손된 데 따른 것\"이라며 \"롯데백화점 본점 식품매장은 햄버거 판매 중단을 즉각 중단하고, 롯데백화점 본점 식품\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(\"지난해 7월, \", return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(inputs.input_ids, max_new_tokens=100)\n",
        "result = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "print(result[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "641ca6f4-49e9-4da6-b42f-05b4aa48b63c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "641ca6f4-49e9-4da6-b42f-05b4aa48b63c",
        "outputId": "4c471500-33cb-4bc7-c764-1ef1da48c289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "지난해 7월, 롯데백화점 본점 지하 1층 식품매장에서 판매된 '롯데 햄버거' 제품에서 대장균이 검출돼 판매 중단된 바 있다.\n",
            "롯데백화점 측은 \"햄버거 판매 중단은 롯데백화점 본점 식품매장의 위생과 안전관리에 대한 고객들의 신뢰가 크게 훼손된 데 따른 것\"이라며 \"롯데백화점 본점 식품매장은 햄버거 판매 중단을 즉각 중단하고, 롯데백화점 본점 식품\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "input_ids = tokenizer(\"지난해 7월, \", return_tensors=\"pt\").to(model.device).input_ids\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(100):\n",
        "        next_token = model(input_ids).logits[0, -1:].argmax(-1)\n",
        "        input_ids = torch.cat((input_ids[0], next_token), -1).unsqueeze(0)\n",
        "\n",
        "print(tokenizer.decode(input_ids[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c319110d-58c5-4514-8acf-752b87b53eab",
      "metadata": {
        "id": "c319110d-58c5-4514-8acf-752b87b53eab"
      },
      "source": [
        "# 5.3.3 Question Ansering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Wcekv857MgXB",
      "metadata": {
        "id": "Wcekv857MgXB"
      },
      "source": [
        "### 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8c5dd42b-52cf-4ce7-a2fc-a810e00e2b73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c5dd42b-52cf-4ce7-a2fc-a810e00e2b73",
        "outputId": "23e4857d-4e30-4ca9-98d8-d535c4f0da3f",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForQuestionAnswering were not initialized from the model checkpoint at skt/kogpt2-base-v2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2ForQuestionAnswering(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51200, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2SdpaAttention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "\n",
        "model_name = \"skt/kogpt2-base-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    bos_token=\"</s>\",\n",
        "    eos_token=\"</s>\",\n",
        "    unk_token=\"<unk>\",\n",
        "    pad_token=\"<pad>\",\n",
        "    mask_token=\"<mask>\"\n",
        ")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zOr0MMgnMimb",
      "metadata": {
        "id": "zOr0MMgnMimb"
      },
      "source": [
        "### 데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "Wj0gmmZR3teW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "be73ec508a284a9aaec489a0346f604e",
            "072559c5ae0149f4b10226381a2a7aff",
            "0d1cdfd69939480ca96e34da5e5baae2",
            "3571f99cca1147dc848cfaa4c861544d",
            "d0434e2d0aac4c87a6583177bfa7305a",
            "ff2e39d9f7c24c818c6260f96f336d54",
            "136241f3edd4417784bc3ed64f7993c5",
            "57e48c0291574fd8a96ee969f640d756",
            "3691cef8f25f47ebaf80719d5b865941",
            "ae2dfd283ff1475a957301dc2ff2e7e1",
            "709bab889b4b423ebd6b220d52de603b",
            "218c97c9a3ec417e9f46b617417005b7",
            "c8d7d611836d46cf860b4718890af306",
            "72d60a1050d049208c3dc9707f478808",
            "78479806058f44db8ee8444b46e94e9e",
            "0186e66de5f14ea59e56b93e839da754",
            "395da5bf6eba45a48b24601b42c04ee3",
            "8f43e00007c74f389e9f130f170f1547",
            "1b1f1c51fa1a4aafab41d1d6ffa187a3",
            "ba3c4fd4f46f417f8734c565e290c21a",
            "50ae74ed94f94241892ea6c756be7b5c",
            "fba75457120a49b5b8d9da7db87c9f5c",
            "2ee8f065c0ab4a408879da69b5f56c81",
            "d0c37bb1b66944eeb6f55cca4e59e493",
            "39c0d685976e4023ac6ed954ce5d7b20",
            "6d5d78e1628941b691d5279a5cf2fb2e",
            "e458ad988f4a4948ac8cb234a243d82d",
            "afbe0bfd41bd43f88657f87155c6f896",
            "2fccdc7ce6da48d3beba7c55b7fb9ba7",
            "030431046fac4a64ae0c2c68c7743527",
            "67d17e18ee7e4bd6ba11242ef275d8cb",
            "5fa141f3ae49498e80eedecb5b3a9742",
            "5162dd4d7e6149c3bf8b608ab5167464",
            "cac60d1f409643a283003a8228792e8c",
            "92203dfa180d4f889f6384186f99b491",
            "2e6e9cd18117421db19cfccde8d74575",
            "858a1a728a0647c5883354a152f87743",
            "ce551a16c69a4fe2b2f9e4fe4835b1a5",
            "fb07d3173b854933a80f71a6f1993eb2",
            "75c5e030cf9847c8b1b964c359e49623",
            "5b219ef8a2b84ccc9eb873c3b04baf56",
            "0b1d905a39204bdca4b50683eebebd2f",
            "38f8be1ffbf64b579d7e7ad4b51164f1",
            "8f9785c73fb54fe29086397ffa621a00",
            "32be17b58ee846c28a59ff5e3e5b369f",
            "8ee8ba35eba14cfda313a1bb6fd81051",
            "d8447aef19e64fb5a564bb1747b8980e",
            "66ab55452b3a485da7640418939a488d",
            "e0c4f8c596204c79b62cb3b65f9c3d24",
            "751d181de6b64adab59aaeafaeae7ae0",
            "45bec734b07b446b94b344df2ffcba63",
            "4fcd2375d406436ea8e033199e0a041f",
            "538ee43f4422492aa33f1c9023057b97",
            "b1b0e6970f7a47d9b57890cde9e6cb03",
            "4138e93010ef4344b42978cb800ea273",
            "e9254af20f0b478aa0a261ebaf92ebb6",
            "3b89636e3e8841b4a5cb8fd3fd164e12",
            "06aad1aecff04718aa5bfc32b1c6d1fc",
            "7056321a09084a89bc5663c12f7404e0",
            "ea6acad0c5a94f03a7de8f0681ed06ff",
            "cb8b73c1a39046038d526eb3f1330a8b",
            "1cd77d4c520b46d092c3644a98e4f6c2",
            "4beda8ed72d7447591bfdbc5353b7e3d",
            "c0c8c1d4541e48ed95730c73276d15ac",
            "3e9c541f36e548a49ecb8a4d913a4df6",
            "25f516bf5d454499949799f61df98324",
            "f423f091f81146dabc451889bf0a0609",
            "75a39c31ecdf488790507ee021ea2cdd",
            "f6aa0ebdb2f84ba187818a74f574408c",
            "239a108045cc4b3fad3ebdd7952c5be3",
            "5e5480897459490d8b5dfd019a15e236",
            "f14d7cfcf7134647a5a837a78c504302",
            "5b3fbc537e1143b8b6bf51495b8cce56",
            "a804ab5b0b0d4db1b9a4c466334612eb",
            "d866c1c23a554093adc1248507874325",
            "2912113e14a1420cbb508290b7d03dd6",
            "63b5701c89f3426783e94aa042aa63a5"
          ]
        },
        "id": "Wj0gmmZR3teW",
        "outputId": "93412b4c-2844-41e0-9217-77968b6256f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/22.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be73ec508a284a9aaec489a0346f604e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "218c97c9a3ec417e9f46b617417005b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ee8f065c0ab4a408879da69b5f56c81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/17554 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cac60d1f409643a283003a8228792e8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/5841 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32be17b58ee846c28a59ff5e3e5b369f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/17554 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9254af20f0b478aa0a261ebaf92ebb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5841 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f423f091f81146dabc451889bf0a0609"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"klue\", \"mrc\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=512,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        try:\n",
        "            while idx < len(sequence_ids) and sequence_ids[idx] != 1:\n",
        "                idx += 1\n",
        "            context_start = idx\n",
        "            while idx < len(sequence_ids) and sequence_ids[idx] == 1:\n",
        "                idx += 1\n",
        "            context_end = idx - 1\n",
        "        except Exception as e:\n",
        "            print(sequence_ids, idx)\n",
        "            raise e\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "U4YnjMt45ID8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4YnjMt45ID8",
        "outputId": "5e6f2399-aa1e-44bf-cc4a-a91a2b63e7a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 9233, 20493,  9032,  ...,     3,     3,     3],\n",
              "         [28567, 15263, 15755,  ..., 40714,  9045, 12446],\n",
              "         [21066,  8745,  9462,  ..., 12446, 42608,  8563],\n",
              "         ...,\n",
              "         [10528,   425, 10355,  ...,     3,     3,     3],\n",
              "         [ 9150,  8160,  7109,  ...,     3,     3,     3],\n",
              "         [ 9751,  9134, 35894,  ...,     3,     3,     3]]),\n",
              " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " 'start_positions': tensor([215,  24,   0,  52,  58,  66, 200, 311, 297, 279]),\n",
              " 'end_positions': tensor([217,  26,   0,  53,  63,  71, 208, 317, 302, 283])}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()\n",
        "batch = data_collator([tokenized_dataset[\"train\"][i] for i in range(10)])\n",
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GV6g4g0SMv0O",
      "metadata": {
        "id": "GV6g4g0SMv0O"
      },
      "source": [
        "### 문장 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4oWWeYqqVU_f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4oWWeYqqVU_f",
        "outputId": "f38c46ef-bad4-4ff7-a8bd-618280cb7b90",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(**batch)\n",
        "\n",
        "answer_start_index = outputs.start_logits.argmax()\n",
        "answer_end_index = outputs.end_logits.argmax()\n",
        "\n",
        "predict_answer_tokens = batch[\"input_ids\"][0, answer_start_index : answer_end_index + 1]\n",
        "tokenizer.decode(predict_answer_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae1227d5-36fd-4b66-95c0-f3b40ceb01d7",
      "metadata": {
        "id": "ae1227d5-36fd-4b66-95c0-f3b40ceb01d7"
      },
      "source": [
        "# 5.3.4 Sequence Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3ef6138-e594-46ad-9d07-d466edad97b9",
      "metadata": {
        "id": "e3ef6138-e594-46ad-9d07-d466edad97b9"
      },
      "source": [
        "## 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8a33aaf8-418f-49b2-8c99-e8fae011aae0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a33aaf8-418f-49b2-8c99-e8fae011aae0",
        "outputId": "2c645c07-e7d3-4f11-f575-f5deeaf86b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at skt/kogpt2-base-v2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2ForSequenceClassification(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51200, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2SdpaAttention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"skt/kogpt2-base-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    bos_token=\"</s>\",\n",
        "    eos_token=\"</s>\",\n",
        "    unk_token=\"<unk>\",\n",
        "    pad_token=\"<pad>\",\n",
        "    mask_token=\"<mask>\"\n",
        ")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8f523a7-be3c-46bc-89aa-c4baee942f1d",
      "metadata": {
        "id": "e8f523a7-be3c-46bc-89aa-c4baee942f1d"
      },
      "source": [
        "## 데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c61a0fd7-2c42-4233-9165-0a105cc8454d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "396ae25252d1453c8421a0da9d5b2e24",
            "659668e593e342ac81606342e931ba57",
            "99ac88b204c94ca3a0d308aa69bd69da",
            "83c28f819e9d40a2a7ad61122eceddf0",
            "667d73c9fe38491dabc991373339c7ab",
            "265d357bbdbe451d91cf04b374a2a356",
            "84f449e88e394fd1b61218e841b48832",
            "5cef600882d7453aafa9827bcfe1a77a",
            "bafc2b9fe389441e90d900df62e1afe0",
            "1523d3608dbd473d80bc7ba06b484f87",
            "9a7bfd340c604931b265ab01ff19daae",
            "c617d1259bbe42e3b26c5a244cc6b21d",
            "2434631ee193434bb3b837b6fe5a41ce",
            "a64bc160643440768b0fdf57800693ad",
            "b368efc67b6b440e9c13ca985c45f8eb",
            "a19a5dc912e04a25844f743e015a0e50",
            "14d3dd5a98ad406f904919da3d8ed738",
            "e77694b12fd945bf8b6e4a8e61809ad3",
            "40b89a2dd6f84d97aeeace6247054c9a",
            "7d96930819fb42c7b77f3c2a5f3eb7c8",
            "47581cdc17b541bd98e40c1e7485fe31",
            "e44b0b64da9b4d09ba8c24e43553c264",
            "4def9b5dd5954f67a71cfd52d9121d98",
            "18b2fef09e6243a2b938bc304c4294b7",
            "96243034dfe94ef3b375e921b83cc527",
            "fa51a597d6214af4a670a38c14c9060c",
            "7bf6394469c54abb875579ca7ed5981b",
            "c86d392ca4154776b2aff679d6f4bf9c",
            "02de9d07d5104b52b1823b2f951666c7",
            "a9cdf77841884cfaa186988cf44ce3be",
            "d7e4cbb25c7b4d9fb650fcad34fc753f",
            "009d938dbb6f41e091d212f04c6c3858",
            "1fcbb97c6bff4464bb317a04ae516628",
            "c52b769709534c68b1ee567a72c89adf",
            "00a02c0ae8484733ac9b158ab7434c4b",
            "9034d6bacaf14f7eb3cacfc145633dda",
            "244bdb91dd6f47bc849e094933dbe45c",
            "6528ae084b704b0884945ea055b21dbd",
            "bd6226fac7e34b5fb88b30d1e933b1d9",
            "f5f8302542594a85a6281931b80e5f62",
            "c2c905897ee946a683c7a979261834e4",
            "6b313add1af2402ba7db83eccec1d395",
            "cea4532ff246435a83a1e9ba38aa23c6",
            "da57726b367e4cb78e201a96795eb861",
            "ad106fb55edf47929f06e1618e1332b7",
            "0535c84d7f234333a521cb35ef66709c",
            "e63358b487c74074833588f4e0881f7c",
            "fcb74d0bc21a47a3ba44111a5c1593e9",
            "a1a490d0e3ba4c9c93d87aac0562c25e",
            "8754e2a1ff0940f29af7a9abaf052eb1",
            "520e5a3891a24aae9b1c92cdb24f7881",
            "8cd76b3409a3443abc5d305c06965a41",
            "092135cffc6141d1a2a4bf3a75fa42ce",
            "6d4cc16345ec4326ba6fb4ea9c20658b",
            "3a3cf9cac542417686c730d0ce703bd2",
            "1c3e4cb4620d4a1893f0a7b829755d27",
            "7babfc3b92b54c46845feadf3365529c",
            "c0c6807e117143419e299b717260bbd0",
            "4842a54a25a544df8fcc8f3a4511a404",
            "fadceff2b37a4640a296e64f25648168",
            "8fb5329b841b4af39f80bfb3edc0574a",
            "2dbe5ff57a754075a5597faa8fc66d3b",
            "ee504e08649e4d8ba7caeb06c1924d8d",
            "f44502be4ec34cb096c728ffae5ca662",
            "d9062751c5f546aca5273718541cc8f2",
            "50ced647aada4f24aaf72bebac4b15c5"
          ]
        },
        "id": "c61a0fd7-2c42-4233-9165-0a105cc8454d",
        "outputId": "398a4a56-b37c-4df8-e4f7-3fb2bc86e2f6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.52M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "396ae25252d1453c8421a0da9d5b2e24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/68.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c617d1259bbe42e3b26c5a244cc6b21d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/11668 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4def9b5dd5954f67a71cfd52d9121d98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/519 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c52b769709534c68b1ee567a72c89adf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11668 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad106fb55edf47929f06e1618e1332b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/519 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c3e4cb4620d4a1893f0a7b829755d27"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"klue\", \"sts\")\n",
        "\n",
        "def process_data(batch):\n",
        "  result = tokenizer(batch[\"sentence1\"], text_pair=batch[\"sentence2\"])\n",
        "  result[\"labels\"] = [x[\"binary-label\"] for x in batch[\"labels\"]]\n",
        "  return result\n",
        "\n",
        "dataset = dataset.map(process_data, batched=True, remove_columns=dataset[\"train\"].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0cebdb82-153d-431a-8bba-4fa38fa36046",
      "metadata": {
        "id": "0cebdb82-153d-431a-8bba-4fa38fa36046"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "collator = DataCollatorWithPadding(tokenizer)\n",
        "batch = collator([dataset[\"train\"][i] for i in range(4)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IKp8FF-zNUZ8",
      "metadata": {
        "id": "IKp8FF-zNUZ8"
      },
      "source": [
        "### 문장 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "95cdb608-80a6-4916-afff-b9e0ef34b111",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95cdb608-80a6-4916-afff-b9e0ef34b111",
        "outputId": "4b124685-ff42-459e-8381-15d2da92fcd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4557,  0.3454],\n",
              "        [ 0.4636,  0.3062],\n",
              "        [-0.0778,  0.5870],\n",
              "        [ 0.2521,  0.4825]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  logits = model(**batch).logits\n",
        "\n",
        "logits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d993abd-1ba0-4a96-9ceb-feaa11eaea46",
      "metadata": {
        "id": "0d993abd-1ba0-4a96-9ceb-feaa11eaea46"
      },
      "source": [
        "### 평가 지표"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8d22ea2e-00df-4e94-b2cf-9c3bf75e1807",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "432135e41fe14c259c3c377be5359f01",
            "fd2d29453cbf43318474a2bb1861628d",
            "c0de02fccd09416b9d9f3d31ecf21efd",
            "8bc96d2226e3446d8cb096bebcdf1066",
            "661f2d66df8b45e2b868400698c837ab",
            "b9c0e4e4b68342e0b0f5060fea3f3079",
            "328cee53e61c4316a83e37c03874bc6f",
            "21c2463979bd49ac897fab417c6f0c82",
            "c565d294e60249b38918238be488a81b",
            "c854c2fdab8f4e2680e6290ef12b84fc",
            "acfbfdcfe7df4448b71155794db49512"
          ]
        },
        "id": "8d22ea2e-00df-4e94-b2cf-9c3bf75e1807",
        "outputId": "8e62f51a-1b7d-4216-8eb0-7cd51460ac8c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "432135e41fe14c259c3c377be5359f01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 0.25}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "f1 = evaluate.load(\"f1\")\n",
        "f1.compute(predictions=logits.argmax(-1), references=batch[\"labels\"], average=\"micro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ruplbeElJZvr",
      "metadata": {
        "id": "ruplbeElJZvr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
   
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
