{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "558d7cce-d205-496a-aff7-1a8674b085d4",
      "metadata": {
        "id": "558d7cce-d205-496a-aff7-1a8674b085d4"
      },
      "source": [
        "# install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "addf4fa2-da59-4dbe-9de2-4da9b6cdcf6c",
      "metadata": {
        "id": "addf4fa2-da59-4dbe-9de2-4da9b6cdcf6c"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn==1.4.2 \\\n",
        "     transformers==4.43.0 \\\n",
        "     datasets==2.20.0 \\\n",
        "     peft==0.10.0 \\\n",
        "     accelerate==0.32.1 \\\n",
        "     bitsandbytes==0.43.1 \\\n",
        "     trl==0.9.6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63a33736-f02c-47cb-bbf0-0f60c10edadb",
      "metadata": {
        "id": "63a33736-f02c-47cb-bbf0-0f60c10edadb"
      },
      "source": [
        "# 7.2.1 LoRA 및 파생 방법론"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KWnyxWNCHnsd",
      "metadata": {
        "id": "KWnyxWNCHnsd"
      },
      "source": [
        "### LoRA 초기화 방법론"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VqYgxL3Q5c9N",
      "metadata": {
        "id": "VqYgxL3Q5c9N"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "config = LoraConfig(init_lora_weights=\"gaussian\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F5Pf0eyeIAT3",
      "metadata": {
        "id": "F5Pf0eyeIAT3"
      },
      "source": [
        "LoftQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ahM-QK85HuXf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432,
          "referenced_widgets": [
            "e5889198c9e34f2c883a553f741b5ca1",
            "7203fe00b6274740bd2efe588ad0afc8",
            "6ec83e97172b47b0af2b0fca5175c0a5",
            "095c4298e4174a249e00ef40258a3c55",
            "5b2a247e661a455592494ffb76fba3b3",
            "80938aff76534fd98c580484038da2ff",
            "0f71a9af90a24308b189f380870800d4",
            "c79b8d3a820642e5bb6bf11f5118c3d9",
            "027cf2a52f24403cab8c2366a0cc7101",
            "75485fa757a94ae7b047ec68b156b86c",
            "e2525dcf461540a3901961ca121e1ec5",
            "a87b82017c634e41a5a44822ae5e4523",
            "ee2b7d2f6db54c6d8920a3fbaabad1cb",
            "38456dcaf9ef44da95f1e3a4fd23226e",
            "1497439e8ba54f548cb36046d8b96721",
            "f2470ee74d6c4aa0b86b204801a2329f",
            "ddb05e16a0f24980bffaa38835b84506",
            "79e2e4b2f4fb42ea98096b4c518d5e1e",
            "890d1fa1d5bb49e1a51745342bb3b974",
            "406b5d42694940bbaf7e70b84a9d5717",
            "097147c6bcf7426abdbe8ae57a9e5266",
            "01da1c430cec4cc6b9e51b8bbec5e012",
            "3a01dab70cc84fdfa8586aeafc9d35f5",
            "9ec0705fbf354305b7cbb7cd28d551dc",
            "0be5de606e7843ebb2d4962481b3ed5f",
            "ad189a9b57824d1b9f3d958978c76c80",
            "1e2a0387803346079d3d0a507c6dc7a8",
            "711098ea83d54e988cf128fd0afb121b",
            "b00998a61a7a4e7bb85962ed86aba897",
            "1992ad29f82b46e0922801d9795392db",
            "d3c49428b7c841778a849a3dc9dd771a",
            "2396dbf395814fe78f264b923da00a64",
            "b2b06d5e2057470c84659309467fb541",
            "77a40bd47a914d649449853eaf3d472f",
            "dae116cf9217470996011e3f60109061",
            "3e05b49f07104246985b1ca3a9f98e9e",
            "59ba832652694d03a2bb0bc056f07db6",
            "067573f05b1e492aac4bd31e8aa0943f",
            "5fe6d5bebae74f239084b1fdaa4cef5b",
            "49ac0f40bdbe49d48061aaafa09f46fd",
            "bef4199a77a145c5b8811f3e800f0a4c",
            "490cc9e5aad04b109fd6a0ec5c1a52b2",
            "b70d694c81344c0b874daf7b2da0f130",
            "631c23be4a5c4fd19b5dd70a1f4eca49",
            "fe2e51f355ae4debb2a0ef78dbc72e2d",
            "728dd169ce65470294f55fa33d11f2d4",
            "34b56aa91ae2425b86024c4b1cc3d9eb",
            "7b8c69dfd9994e1483358c25dcede2a0",
            "1caeff5069c64cac846c58d863675763",
            "95a670d384224b69a315482fe163aaf3",
            "a345f338bd8e41c181938dbd0c30f8ca",
            "baf0bd80636648f89bffd1a5c69263f8",
            "5a39342ab99e4023b42d079f8d3dd34e",
            "7902f79aa74849e596dd28b3e53921b5",
            "97aacfadb5df4be7bc497c58a350f0d0",
            "c1ed9d82de764e05865b022d97325daa",
            "f628264496b846898c3aed0d896b0d10",
            "c919a28720584de3a714df8d34181125",
            "d1c0845b00d947f7890d1ad0a74230cb",
            "ed54d16e3cad4999b51411da9cc70b77",
            "57a8ea7999b64bfd960a0951c11e16b6",
            "40507006bd024e888614f78c600fe97f",
            "add0215ab8ce49d384add71210fc698a",
            "ef65c4d8f5f74384bd1d6058e6b7b62f",
            "a9793d7ef59a4062b2d02f45b77c685e",
            "b8d7e36a87d740e0937cabe971e40b76",
            "b4d48634997044b78218c74f1e09ca61",
            "db55364d197b45f0a656956455f6eb07",
            "caae4e0576ac4577816bf6b78d7c5c66",
            "4d34e50b20654ada998dc282f44cf73e",
            "44d86268fbf04d60bf61eba751720c41",
            "5326ce877d0f45edae0321292179c18e",
            "376f094d2f504af7a4cf35cc64d7b3ee",
            "521583d3f5914f728459e31e853337bb",
            "93c33809366c4edb8bc5d400ba467869",
            "8e54914d2e074c5cb291cf39371ccf93",
            "478b8212e06a47648871cab406a7ef74"
          ]
        },
        "id": "ahM-QK85HuXf",
        "outputId": "e4871da2-d203-46f6-80b4-35a403016ca2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5889198c9e34f2c883a553f741b5ca1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/676 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a87b82017c634e41a5a44822ae5e4523",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a01dab70cc84fdfa8586aeafc9d35f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77a40bd47a914d649449853eaf3d472f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe2e51f355ae4debb2a0ef78dbc72e2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
            "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
            "`config.hidden_activation` if you want to override this behaviour.\n",
            "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1ed9d82de764e05865b022d97325daa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4d48634997044b78218c74f1e09ca61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from peft import replace_lora_weights_loftq, LoraConfig, get_peft_model\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"nlpai-lab/ko-gemma-2b-v1\",\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "lora_config = LoraConfig(\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=\"all-linear\"\n",
        ")\n",
        "peft_model = get_peft_model(model, lora_config)\n",
        "replace_lora_weights_loftq(peft_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PKnLReh521Vz",
      "metadata": {
        "id": "PKnLReh521Vz"
      },
      "source": [
        "Rank-stabilized LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "innvq8Sp3M6h",
      "metadata": {
        "id": "innvq8Sp3M6h"
      },
      "outputs": [],
      "source": [
        "config = LoraConfig(use_rslora=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TdbAca3OY8xG",
      "metadata": {
        "id": "TdbAca3OY8xG"
      },
      "source": [
        "Weight-Decomposed Low-Rank Adaptation (DoRA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q18OdjjfY7NE",
      "metadata": {
        "id": "Q18OdjjfY7NE"
      },
      "outputs": [],
      "source": [
        "config = LoraConfig(use_dora=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "S9EwVkjVa05V",
      "metadata": {
        "id": "S9EwVkjVa05V"
      },
      "source": [
        "QLoRA-style training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "slGzRVpqa53-",
      "metadata": {
        "id": "slGzRVpqa53-"
      },
      "outputs": [],
      "source": [
        "config = LoraConfig(target_modules=\"all-linear\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UUcI_RPJcBg6",
      "metadata": {
        "id": "UUcI_RPJcBg6"
      },
      "source": [
        "Memory efficient Layer Replication with LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "An-Q73_CcEFA",
      "metadata": {
        "id": "An-Q73_CcEFA"
      },
      "outputs": [],
      "source": [
        "config = LoraConfig(layer_replication=[[0,4], [2,5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54dab824-6a3b-4e44-9e93-51fc44bbb16a",
      "metadata": {
        "id": "54dab824-6a3b-4e44-9e93-51fc44bbb16a"
      },
      "source": [
        "### Save adapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y5-4Z2snu5Bv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295,
          "referenced_widgets": [
            "d72a946481824920bcf7bf20614840ba",
            "c26970344d40452d9b53c282c44f3951",
            "3b1fb01919c34c45b4a724a9027a2c24",
            "d43bb3d5782c4755afda718d8e97fd05",
            "ff2064d4a9bd4592b59865466fd25fcf",
            "4611a2f44a43491cb5446166874f69bd",
            "965257dd93ff4999afcbf8032ca65cf0",
            "118049f582594ec288989d7e05e2c628",
            "4f1dc30f51944e759f77d8c50f6f940b",
            "e9bdf519be504d0aad3fb3636fe5d6f9",
            "eca670323b094285a1643ceccdce0b6d"
          ]
        },
        "id": "Y5-4Z2snu5Bv",
        "outputId": "b6a069f3-e273-4c24-a58e-2a03a59fc102"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
            "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
            "`config.hidden_activation` if you want to override this behaviour.\n",
            "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d72a946481824920bcf7bf20614840ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 921,600 || all params: 2,507,094,016 || trainable%: 0.0368\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoConfig\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "# 모델 로드\n",
        "model = AutoModelForCausalLM.from_pretrained(\"nlpai-lab/ko-gemma-2b-v1\")\n",
        "\n",
        "# peft\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "    inference_mode=False,\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        ")\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# 모델 저장\n",
        "model.save_pretrained(\"/content/peft\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0lJdahjpFt4W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lJdahjpFt4W",
        "outputId": "f81a2596-f2ba-4897-912a-5d88f392edf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "adapter_config.json  adapter_model.safetensors\tREADME.md\n",
            "3.6M\t/content/drive/MyDrive/Books/outputs/peft\n"
          ]
        }
      ],
      "source": [
        "!ls /content/peft\n",
        "!du -sh /content/peft"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lTSqu-KLN9pS",
      "metadata": {
        "id": "lTSqu-KLN9pS"
      },
      "source": [
        "### Merge adapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ozUo5Vo7OANs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694,
          "referenced_widgets": [
            "7894a8054880450c909a258b42b3f203",
            "1545321dc18447e698690ebeddc31691",
            "1df3091888754291918c079d3e1dfa3e",
            "997d8e16b4544644b6236aa7538f11a2",
            "dac52003f0b84f208c3c86603e532f1c",
            "c67d93bf23164579b15d1b230ec89bca",
            "8944a14428ad4b23a7d572884c918e92",
            "ca67c77f57f7463f85f54b410162a7e4",
            "ddc07d1fb0ba45a6828e421e4a77f15e",
            "05e8b06427594b90b7bcf3e64522bb8e",
            "a09c36adbbc54f5099548dea1c9c3759"
          ]
        },
        "id": "ozUo5Vo7OANs",
        "outputId": "145a0a9b-6f49-44da-a56e-0206c28c97b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
            "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
            "`config.hidden_activation` if you want to override this behaviour.\n",
            "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7894a8054880450c909a258b42b3f203",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "GemmaForCausalLM(\n",
              "  (model): GemmaModel(\n",
              "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-17): 18 x GemmaDecoderLayer(\n",
              "        (self_attn): GemmaSdpaAttention(\n",
              "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
              "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
              "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (rotary_emb): GemmaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): GemmaMLP(\n",
              "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
              "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
              "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
              "          (act_fn): PytorchGELUTanh()\n",
              "        )\n",
              "        (input_layernorm): GemmaRMSNorm()\n",
              "        (post_attention_layernorm): GemmaRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): GemmaRMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"nlpai-lab/ko-gemma-2b-v1\")\n",
        "peft_model_id = \"/content/peft\"\n",
        "peft_model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "peft_model.merge_and_unload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2kxerMz7QiK5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "db13bdea85d24ea5bf90277a334cd06d",
            "cca5d3012b2445328c972fe0b86b8f37",
            "8e49dff26a5b48f583636fdfd27ca725",
            "26bb15d8c8974fd5a5d67210684c388e",
            "bcc62f64bc614500b9ce785d7659b499",
            "b17157fb76864c9798634a2252fdaded",
            "14f2efa625324b778ca91b839a4f9d42",
            "4f9e927009224931af9cc997288e79eb",
            "b15dbc2787fe49dab4b02a5f6aee95cf",
            "1ed4ef12aad6432691f73401e08ee6dc",
            "0d9ce11a48a74a78960a14708ebd4916"
          ]
        },
        "id": "2kxerMz7QiK5",
        "outputId": "9f9b821b-d6a5-49fa-a8f1-b3ca2809bb5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
            "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
            "`config.hidden_activation` if you want to override this behaviour.\n",
            "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db13bdea85d24ea5bf90277a334cd06d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"nlpai-lab/ko-gemma-2b-v1\")\n",
        "peft_model_id = \"/content/peft\"\n",
        "model = PeftModel.from_pretrained(base_model, peft_model_id)\n",
        "model.merge_adapter()\n",
        "\n",
        "model.unmerge_adapter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RtPKgPH4R_4g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4eff3e3cb75c4ecba393055fb47e90dc",
            "d9af6a23157b40389e7ae28528f2ee73",
            "7a893e28a8c440f99f3858c135badb98",
            "1dfe4346b0cb46cea43b0ed6a79ee8f2",
            "34748e33442e4d7686092c8c29c2f07b",
            "26fc989deb3e437a8bfc466c090f1a00",
            "74d26b410be74c918a12d32e198e65cb",
            "826b90ec5ff44cf5b0a024ddd557ad92",
            "411de9819d5a4dd8bdf0f205ee146e47",
            "180f9ca93f29489a9de06c7e9430faa6",
            "49ed2ba53ab642d0802cbc1076310a69"
          ]
        },
        "id": "RtPKgPH4R_4g",
        "outputId": "da8428ed-5706-4bc4-e105-d26cc5286bc6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4eff3e3cb75c4ecba393055fb47e90dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"nlpai-lab/ko-gemma-2b-v1\",\n",
        "    torch_dtype=\"float16\",\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "peft_model_id = \"/content/peft-a\"\n",
        "model = PeftModel.from_pretrained(base_model, peft_model_id, adapter_name=\"a\")\n",
        "\n",
        "weighted_adapter_name = \"a-b\"\n",
        "model.load_adapter(\"/content/peft-b\", adapter_name=\"b\")\n",
        "model.add_weighted_adapter(\n",
        "    adapters=[\"a\", \"b\"],\n",
        "    weights=[0.7, 0.3],\n",
        "    adapter_name=weighted_adapter_name,\n",
        "    combination_type=\"linear\",\n",
        ")\n",
        "model.set_adapter(weighted_adapter_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vDojGokcUcat",
      "metadata": {
        "id": "vDojGokcUcat"
      },
      "source": [
        "### Load adapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WuO2yGgDUi3-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c3909e8385304c20bd6c30b359ebe3fb",
            "ab46ce41fa6a4a63baabad94b37fe9aa",
            "f161867e95134eba979a3196cfd55e0e",
            "f609dc725f2544a5b0c306f135debb5a",
            "7fed67ff6d834c4cb6295cd7a82a1fc9",
            "b76d17bb2da94fdd8df086234b0e9034",
            "8b924f6276e5434a86af27ff9c30899c",
            "435e2fa7f7a14ad4a9d340f5fccf2595",
            "4e847bd9c32442c29454c2c4c33a1fc3",
            "5d265fe45b724fe0a3187707e05e1273",
            "84fff34fc7944ec3a3fc230ebc907149"
          ]
        },
        "id": "WuO2yGgDUi3-",
        "outputId": "90037f79-53c6-4e24-ec4a-4b09d6df1009"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3909e8385304c20bd6c30b359ebe3fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"nlpai-lab/ko-gemma-2b-v1\")\n",
        "model = PeftModel.from_pretrained(\n",
        "    base_model,\n",
        "    \"/content/peft-a\"\n",
        ")\n",
        "\n",
        "# 다른 어댑터 로드\n",
        "model.load_adapter(\"/content/peft-b\", adapter_name=\"b\")\n",
        "\n",
        "# 활성 어댑터 가중치 설정\n",
        "model.set_adapter(\"b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0NzCkl-uXeB0",
      "metadata": {
        "id": "0NzCkl-uXeB0"
      },
      "outputs": [],
      "source": [
        "# 어댑터 언로드\n",
        "model.unload()\n",
        "\n",
        "# 어댑터 삭제\n",
        "model.delete_adapter(\"b\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Wb5oH6UBDkMp",
      "metadata": {
        "id": "Wb5oH6UBDkMp"
      },
      "source": [
        "### LoRA 모델 추론"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T9bfILwSmo_X",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408,
          "referenced_widgets": [
            "53f2e72015ba47bf8ef1a87b5ae9d228",
            "7ccb23c878d7469281c9c888b28875fe",
            "fa85f26a7f644cb8902126d0cc1e7e18",
            "c88bdd2fec6547dba0e091dc50940e80",
            "88af382b281a4674a1ae83129a753ed1",
            "f8e2eb18d3a94d669073dfd0c50e4709",
            "ec321162eac14b2aa7e5b953138d55b4",
            "e10375fd60534cb5a61a715a54218039",
            "2ef5d5e8f72c4b3f8975b90366d2306c",
            "99159ac659ff4e8396331faf508aee80",
            "625f0414c11a404282fccf5e210458e1",
            "6bcffc049cdd47e2b7f319e47e088456",
            "e01b10552250452280ba789b23f33098",
            "32b96a30bdb64b1f8d11a250ae1f0193",
            "db667443635b44538eb1c0b1ed184e1b",
            "7d46ee8f2436425aab4ab1a3050819cc",
            "2edbb80a5b504a13803e39990d880076",
            "7f6a072661564ec0a64703eab2e6c911",
            "711ff2a0688741bab36b3c632c2d9427",
            "9a18148885414940931f1b72af4a4f87",
            "88663b5943544a14a8500ca2a1b062d5",
            "c6bc38b90ea242d68a664df8ace3b416",
            "6499094c502a41faaafcf73cbdeb738c",
            "139ff499b2f64d3db37f0b1ce78feb81",
            "8a771663121c41ccb1ec313ad0051fa4",
            "c42b51006e9340a18490b20b606b322d",
            "93834f3b8f454a8989197d7acac0cd71",
            "5aacebd881dc46388e6b889a63181c7e",
            "4bf03489b71f4c23b6deb175e511c307",
            "bb87c2e38fe14e97bee98d443af433f8",
            "5e654d3d60224f50ab0f3803298c45a6",
            "06180dec7d1e4fca9bfaae3dde8f7e27",
            "cf66b6bbaa7649a0acacf78c9e8cf228",
            "d429bba4c039499d832a29e3cd8604d0",
            "eb46d81eebf542b7a694d7b2e5fd7b13",
            "3e84b0ac1e14410b8355141875374bf0",
            "314e2f1aec994b8884e61e850bcd740b",
            "a9c5dbe046fc4cd5a56122975945ec0d",
            "a11b8f630a124f17ac4ab9842b65ae63",
            "028d39e03bf44f23be642c545410951f",
            "58249ffab2e14282ac968b4c0d40d392",
            "1cd86a6a472343fca48ae00ed6b8ca38",
            "baa3827c9211492f879d516d8b569bee",
            "5369a56c906f4788bae87cb95f6b5371"
          ]
        },
        "id": "T9bfILwSmo_X",
        "outputId": "04acc5df-bf16-42cc-b7b3-608e8c8cd0d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
            "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
            "`config.hidden_activation` if you want to override this behaviour.\n",
            "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53f2e72015ba47bf8ef1a87b5ae9d228",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bcffc049cdd47e2b7f319e47e088456",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6499094c502a41faaafcf73cbdeb738c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d429bba4c039499d832a29e3cd8604d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user\n",
            "대한민국 국보 제 1호는 무엇입니까?\n",
            "model\n",
            "대한민국의 국보 제1호는 \"무표정 조종사\"입니다.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "peft_model_id = \"/content/peft\"\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path)\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "model = model.to(\"cuda\")\n",
        "model.eval()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"user\", \"content\": \"대한민국 국보 제 1호는 무엇입니까?\"},\n",
        "    ],\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "gen_cfg = GenerationConfig(\n",
        "    max_new_tokens=2048,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.92,\n",
        "    return_full_text=False,\n",
        ")\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(input_ids=inputs.to(\"cuda\"), generation_config=gen_cfg)\n",
        "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZB19S0Fha0sp",
      "metadata": {
        "id": "ZB19S0Fha0sp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
   
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
