{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "558d7cce-d205-496a-aff7-1a8674b085d4",
      "metadata": {
        "id": "558d7cce-d205-496a-aff7-1a8674b085d4",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "addf4fa2-da59-4dbe-9de2-4da9b6cdcf6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "addf4fa2-da59-4dbe-9de2-4da9b6cdcf6c",
        "outputId": "db9286e7-0da0-444c-9cfd-cb7f41716897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==2.20.0\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting evaluate==0.4.0\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting scikit-learn==1.4.2\n",
            "  Downloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (17.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.20.0)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.20.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (4.67.1)\n",
            "Collecting xxhash (from datasets==2.20.0)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.20.0)\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets==2.20.0)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (6.0.2)\n",
            "Collecting responses<0.19 (from evaluate==0.4.0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.2->datasets==2.20.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2024.12.14)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.20.0)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.20.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.20.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.20.0) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.20.0) (1.17.0)\n",
            "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow-hotfix, fsspec, dill, scikit-learn, responses, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 evaluate-0.4.0 fsspec-2024.5.0 multiprocess-0.70.16 pyarrow-hotfix-0.6 responses-0.18.0 scikit-learn-1.4.2 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# 적용 후 런타임 > 세션 다시 시작\n",
        "!pip install -U \\\n",
        "     datasets==2.20.0 \\\n",
        "     evaluate==0.4.0 \\\n",
        "     scikit-learn==1.4.2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63a33736-f02c-47cb-bbf0-0f60c10edadb",
      "metadata": {
        "id": "63a33736-f02c-47cb-bbf0-0f60c10edadb"
      },
      "source": [
        "# 5.4.2 Conditional Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54dab824-6a3b-4e44-9e93-51fc44bbb16a",
      "metadata": {
        "id": "54dab824-6a3b-4e44-9e93-51fc44bbb16a",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "030280e5-86cc-4e9a-b977-f268b181682c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "88c1a731c8a049a4acc745f7c489d8d2",
            "61dc991782a94f0786272a9bef51d505",
            "aca34d5c88054a3d91050acffea77d4e",
            "58a9d9f38b2f4975b0e7751160da8b76",
            "38fd91617bb640cebaf674db32d49d05",
            "0e6062cac65645fbba558f189c306dbe",
            "a44b3d09862041a3a591ca3d3833dca7",
            "2f05279fed034d9b91022d39d3d541c6",
            "510bd652ac8b4695b5426c737c2887e9",
            "cf2d653a1bc94528b4e8ccfde0d618ca",
            "cf5712e27c2c47ce81740a64d2cde4f1",
            "8a0705eaecf24ac19ca6cf6e84521f0b",
            "43598c7fb5c847928b9904d52153578e",
            "d5f9030c65034427ad8e69851bbb9f8f",
            "bafe4c89f59947afbc9281480eba9a94",
            "f4d2f792cfec45468e68f9b0372e44e8",
            "73e72b8af3814572a5ff976564303d7a",
            "39a79f07c2094ba3b5d49d9a1161f4c5",
            "c3e2250979d448e9bc496248bc122591",
            "58bdd0fdb2ba4a91a88d7fb729e8cda8",
            "a3877dd877494452b1d2023c562edb47",
            "0158ae0fd36446bfbc130dc733d3b794",
            "e7ef08c4fe804c6eb5f3b4d7ea067294",
            "3b7c1993eb464ec490b38235754136d9",
            "cfe8ce6dec284690b21f40ca70d15942",
            "d61a9c2d7a114147b94e12db3c0b16d4",
            "dc53fe755b12457193ce8c3a1da78abb",
            "c288eed4f5034a039c7a007032cce06e",
            "f10b82b692ad48ed905924e457aa3a53",
            "485f2bf8c4a24062b46f239da820e62d",
            "952f77d9255f4bd880df188b2dce32fc",
            "388ecea5fe56457f9deac1330a955d58",
            "f00be099ab5c41f885c557ce655b5169",
            "3787c5848e96428082a28714b294a28f",
            "c301f895cfef412586e4b3d926fab584",
            "43f40f91421c433ebeb8439724b04ada",
            "f1179397612b449b834f6ff699b2767d",
            "3ed9d32401034ccc9e0ea5a1a62c4924",
            "b01339d41002436e8c9d8cc9213ecd5e",
            "29470cdeef5242d48f9956e320cbfbe8",
            "8bb7f0aa15c64cad9134bc18256e1565",
            "911276cd42e04262b5fce772e7d8c756",
            "2c3441cd0ce64c4a8b79b3d777a8d48c",
            "a0ae55006b464ae1a15171eb623b5cbb",
            "fd8bbdf32e8343ae87b6b14050b6938d",
            "47966f7c49bc41898cef8cd66cdb1ef3",
            "ff88f8a06e7b4a6ba9268fe8f1cf3497",
            "a0debd705b214bbbbc31be3b06c7671e",
            "54e6179a0e324e0eae233426abb46f60",
            "0cb0ffe2531c4464883ffeaa81bf33f4",
            "bc469d41b8c844c88e3a0e37a626e7f2",
            "47a49bacc0374045ac504d82245a7526",
            "b7926d95557848309e8eba64c54d8ea9",
            "dafb0e7b1e48411ea73a43acbc707498",
            "45bcec10e95e4af9b017d23ca9093d06"
          ]
        },
        "id": "030280e5-86cc-4e9a-b977-f268b181682c",
        "outputId": "14d0ac64-2a2c-4a71-cdac-6ba1ee926e42",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/337 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88c1a731c8a049a4acc745f7c489d8d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a0705eaecf24ac19ca6cf6e84521f0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/109 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7ef08c4fe804c6eb5f3b4d7ea067294"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3787c5848e96428082a28714b294a28f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/496M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd8bbdf32e8343ae87b6b14050b6938d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartEncoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartDecoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"hyunwoongko/kobart\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "004a7c77-0866-4b13-b462-c9dd1813272d",
      "metadata": {
        "id": "004a7c77-0866-4b13-b462-c9dd1813272d"
      },
      "source": [
        "### 데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "44858dcb-3b4c-4a10-b781-c2a4b12de839",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540,
          "referenced_widgets": [
            "950a65a997d441adaaf65fbc1ce359ae",
            "bda871a313b14fd5ac1e59a41e32475d",
            "8d9b5c604abc47c9b993ba53dd02c7f3",
            "80b06f0d6c6d457dab06c3b6e2bed639",
            "8c788db2ae974599a099c126e73d4b31",
            "c04c34c03c8d42cb84a61bd58162cf1b",
            "37c6b45852b34210ac3a586a67ad28cf",
            "170644b2ba654bb5a48e9c126a1c9d61",
            "97463154bb534c14b2ac309c876fdc6d",
            "98f94b65759a4e0eac2695fd869b4bd4",
            "9f151788129f43ed85afb0c860b2c351",
            "12d875c65a274aa6947e48f73247f3b3",
            "bf83fa2f7c27486e95fc8926e99839c4",
            "93de1c44d1c9446abe53b68953bd31e6",
            "b4dc48fb91ba4b9590c1f2c275e071bd",
            "87a6a60345134e38876e6d4934c31a0c",
            "5fc016707e4743c88a38cdc834a74b19",
            "2d551094eaf442e19e4a5a0289a65fe9",
            "fd4a20ecfa8443c4a4196846b0d7cb0d",
            "a4138e9d7ae849359bade380c557a972",
            "3ba4c20af66c406d99726566ec42e3e9",
            "f4460c7d359a40b5910cce3e1ad1ded2",
            "1d615cbaac4e4b8cba81cf1cf1e01d63",
            "0b34118d1b314c2f97c4baeb4f284052",
            "fed92d5531004133b071757669f08469",
            "2e17ba28ef7d4287a016c7afb0501a68",
            "f22f0f9ea086496da325a7f6630d2ddd",
            "631024f862914617bf5543b3f3f998b3",
            "5e6c43fccf6a4696b6e5e49d47daeae8",
            "2605e436fd18439ca6dc1782ff76c093",
            "0d51dcc52e1845748f6a464e6aa6cd21",
            "6e57efba82ec459e8ca28d7608b46ebe",
            "f92d59a147b441268c2abfb54a87f047",
            "118568ca22894aa7b9d1ba433d86b5c4",
            "007bad4b283448799b99c954e6887631",
            "ee0f673fd36847fab886684aa525ac8b",
            "dc2ffeef4d8b49a1bd7d2582d5811ff6",
            "fe11c23283e748ef9dd593321ca0b531",
            "439f42148e134f4388cbb0ed6453ae29",
            "0be1d239237c4bbba61d6f74ea316184",
            "461c54673ed148b8b2e9c242941243e9",
            "4de74b1550414026869c229888456f6d",
            "b52621d5eabe4070bef0f8bce6af82c6",
            "17f46dca65e8403cbd6156144c6b2c09",
            "b6414a3b348a488aa740f77c26e55437",
            "4dd0123d30ea4a5aba7dcf7d7c2958b7",
            "53a9603bf8b94867af292978b3ee9c49",
            "436c1b0dc55f43c59b059bcd1291202c",
            "6f026d6e27ad41788c5afdeb0fcfef45",
            "387e351013d4498384b10688ea19390b",
            "4e2f9bc3665c4c5e87ed1f2399ce210c",
            "c2515b442f9c42388780c1ccd721ecbd",
            "495b6ee8e4134f44ad27bb726265bd6b",
            "b4993efa9de742f9beeb920c96897410",
            "d70d62e4abd54d2ab9b4b57b8131e52d",
            "bbd1424adf0844baa6f68180d6014703",
            "d31418e6b21346bfbe0a4d9068671606",
            "040cd2e9c469429db5e0d04cd65bd27b",
            "7ee669e025294153b9c5b395ea77edfa",
            "fd958d90d651426cacb4bc32c4ea0ed2",
            "acdb2a9c716d49fb9fd17dc0d9df5925",
            "bb7023e6f3da4e9f937dcefcef9fb8b5",
            "c126582a20be4c8ca44b00e22efb514d",
            "13a75e3ee63549fa8babee464b7f1fd5",
            "43bc299062024d61b091bf433b2ffdf8",
            "361cc5aaa70e47b199fd44780fefb8ba",
            "362a8c984b424014936ae39e48aa3d2e",
            "73ae324898c8495f8958dac4ed7a4273",
            "4f0c074cb0ad40e1b5d876e668c5a43f",
            "e762e9cb6fcf4744b489141f210009ed",
            "7f154cb0ddbd47999de2db32bfc8af01",
            "cec39c9049774151a07d9a8f41c12bd6",
            "c6aa5aa7f3a94344ab7824e497cc913a",
            "493f71e5c8d648adbb04ca6d2b072032",
            "c208f50a2ad54fc99468def488765730",
            "0baf03b1e48d420687e3ec025695ff91",
            "f93de4442d814a75a23e28dc1df260f9"
          ]
        },
        "id": "44858dcb-3b4c-4a10-b781-c2a4b12de839",
        "outputId": "02dc3280-0ef5-460b-dbd2-02258cdb8696"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/2.69k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "950a65a997d441adaaf65fbc1ce359ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/41.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12d875c65a274aa6947e48f73247f3b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/461k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d615cbaac4e4b8cba81cf1cf1e01d63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/448k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "118568ca22894aa7b9d1ba433d86b5c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/166215 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6414a3b348a488aa740f77c26e55437"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1958 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbd1424adf0844baa6f68180d6014703"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1982 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "362a8c984b424014936ae39e48aa3d2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['korean', 'english'],\n",
            "        num_rows: 166215\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['korean', 'english'],\n",
            "        num_rows: 1958\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['korean', 'english'],\n",
            "        num_rows: 1982\n",
            "    })\n",
            "})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'korean': '(박수) 이쪽은 Bill Lange 이고, 저는 David Gallo입니다',\n",
              " 'english': \"(Applause) David Gallo: This is Bill Lange. I'm Dave Gallo.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"msarmi9/korean-english-multitarget-ted-talks-task\")\n",
        "print(dataset)\n",
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "68f49c5b-3e18-4d2a-bb1b-65b23e8b9d50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8216a0aee94947f4bfb65502c71ff610",
            "a48ba4608461461e8f97d5f7391fa184",
            "30263673429f44209b972d0d4597a626",
            "b74b0135898a4234877f5f2393f7c6c9",
            "6ac9595954054188806fbcfd58cd9e62",
            "09fbd8b4a604463087e3ce7a873322cd",
            "ffe1ee18cdd547e3ac8da5ca2819d54a",
            "e37e6638fe3e492b894f4d9c36a9fcf6",
            "b071be156e8143ed998cc14a27de9276",
            "f81d13936eed4956aa8b8a187f125af8",
            "af3c80333e8f4d988966b6b1d9299e37",
            "35c2e35f2a3947308ce0586eeea681b5",
            "2d5dce644440454f81cf49a2257e94bd",
            "9350702bd2b64aa39783f5adc5ce5da9",
            "266b1ded70a84e2c8760c3aefd8f6a8f",
            "2edc05c699d44933bbbd7ad2f22ee631",
            "ef458e6ca79b4fa88f70c98ef4a6c51f",
            "f96972882f154d7d9f6df4f1e5afa721",
            "a2ad6e5dc65d4df68c553d6385de043f",
            "354ae843017840c6bb2a4c4c7f5b7dfb",
            "e8809ecb6ede4e0eae8dbaa81472a526",
            "fa48bf85852345b1a9ea966840083555",
            "75fab12567804732a96e9930df84ba72",
            "bb932808fd3545bc9a4bd1a9b6ddfd39",
            "eb332ba829b84465a1b2fa1d47a8fb6c",
            "d5a34786da7c40febba08e00284f6100",
            "2d0d53f16013497e8dd3180d30ceb60a",
            "3f50311dfa1847c0821b0aef0a9c8b58",
            "4b8bbee478ef4d9ba08650a6438b72a3",
            "0d38a88897b047579ac0915294f4a359",
            "23f67f8a5b3f4164932ebda1ce899b55",
            "a9654f80071e4c5f9fc05bae76c48dfe",
            "fa6931da1e894fab848e074e763dbc0b"
          ]
        },
        "id": "68f49c5b-3e18-4d2a-bb1b-65b23e8b9d50",
        "outputId": "fa067b09-f12f-427d-ab47-841855132f1d",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/166215 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8216a0aee94947f4bfb65502c71ff610"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/1958 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35c2e35f2a3947308ce0586eeea681b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/1982 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75fab12567804732a96e9930df84ba72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [0,\n",
              "  14338,\n",
              "  10770,\n",
              "  11372,\n",
              "  240,\n",
              "  14025,\n",
              "  12471,\n",
              "  12005,\n",
              "  15085,\n",
              "  29490,\n",
              "  14676,\n",
              "  24508,\n",
              "  300,\n",
              "  14025,\n",
              "  14161,\n",
              "  16530,\n",
              "  15529,\n",
              "  296,\n",
              "  317,\n",
              "  18509,\n",
              "  15464,\n",
              "  15585,\n",
              "  20858,\n",
              "  12049,\n",
              "  20211,\n",
              "  1],\n",
              " 'attention_mask': [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1],\n",
              " 'labels': [0,\n",
              "  14338,\n",
              "  264,\n",
              "  311,\n",
              "  311,\n",
              "  17422,\n",
              "  316,\n",
              "  17223,\n",
              "  240,\n",
              "  15529,\n",
              "  296,\n",
              "  317,\n",
              "  18509,\n",
              "  15464,\n",
              "  15585,\n",
              "  20858,\n",
              "  257,\n",
              "  15054,\n",
              "  303,\n",
              "  15868,\n",
              "  1700,\n",
              "  15868,\n",
              "  15085,\n",
              "  29490,\n",
              "  14676,\n",
              "  24508,\n",
              "  300,\n",
              "  245,\n",
              "  14943,\n",
              "  238,\n",
              "  308,\n",
              "  15529,\n",
              "  296,\n",
              "  21518,\n",
              "  15464,\n",
              "  15585,\n",
              "  20858,\n",
              "  245,\n",
              "  1]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "tokenized_dataset = dataset.map(\n",
        "    lambda batch: (\n",
        "        tokenizer(\n",
        "            batch[\"korean\"],\n",
        "            text_target=batch[\"english\"],\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "        )\n",
        "    ),\n",
        "    batched=True,\n",
        "    batch_size=1000,\n",
        "    num_proc=2,\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        ")\n",
        "tokenized_dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a0b1461f-c5b3-489b-bebe-e9643c19380c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0b1461f-c5b3-489b-bebe-e9643c19380c",
        "outputId": "c009ad19-4181-4cb2-afee-4312546ca627"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    0, 14338, 10770,  ...,     3,     3,     3],\n",
              "        [    0, 15496, 18918,  ...,     3,     3,     3]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[    0, 14338,   264,  ...,  -100,  -100,  -100],\n",
              "        [    0, 14603,   309,  ...,  -100,  -100,  -100]]), 'decoder_input_ids': tensor([[    1,     0, 14338,  ...,     3,     3,     3],\n",
              "        [    1,     0, 14603,  ...,     3,     3,     3]])}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,\n",
        "    model=model,\n",
        "    padding=\"max_length\",\n",
        "    max_length=512,\n",
        ")\n",
        "batch = collator([tokenized_dataset[\"train\"][i] for i in range(2)])\n",
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-x9qVLU4ONKk",
      "metadata": {
        "id": "-x9qVLU4ONKk"
      },
      "source": [
        "### 문장 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "00dea6a4-e38f-428f-9219-bd330760ba33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00dea6a4-e38f-428f-9219-bd330760ba33",
        "outputId": "ad05be99-46e6-4fbd-a38b-58165e465eac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[  5.4885,  18.7849,  -0.5489,  ...,   0.0465,   0.5813,  -2.2851],\n",
              "         [  3.7287,  18.9676,  -1.1747,  ...,  -0.2600,  -3.4647,  -0.0973],\n",
              "         [ -1.2976,   8.6322,  -5.0410,  ...,  -7.0689,  -6.1345,  -4.4141],\n",
              "         ...,\n",
              "         [ -9.2639,   4.4483,  -8.4507,  ..., -12.6962, -13.2626,  -7.7570],\n",
              "         [ -8.4582,   4.9267,  -7.2173,  ..., -11.5651, -11.8800,  -6.8108],\n",
              "         [ -8.3191,   5.2100,  -6.8817,  ..., -11.1564, -11.7053,  -6.7644]],\n",
              "\n",
              "        [[  4.7748,  16.2666,  -3.0011,  ...,  -0.8965,  -3.3187,  -3.1041],\n",
              "         [  0.6535,  19.3665,  -1.4506,  ...,   0.1562,  -4.3977,   0.1983],\n",
              "         [ -5.0934,  10.8673,  -7.5637,  ...,  -6.3808,  -1.6471,  -7.2105],\n",
              "         ...,\n",
              "         [ -1.5132,  19.0760,   0.3273,  ...,  -2.6680,  -3.9969,   2.7316],\n",
              "         [ -2.3757,  20.0047,  -0.5301,  ...,  -1.7740,  -5.1750,   0.8077],\n",
              "         [ -2.2504,  19.9756,  -0.4518,  ...,  -0.6849,  -5.1071,   0.4721]]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**batch).logits\n",
        "logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bd81c466-f2d5-441d-880c-c223251dc0d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd81c466-f2d5-441d-880c-c223251dc0d4",
        "outputId": "19ed2b1c-8a03-4978-ff0e-b3690eae6699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "from transformers import GenerationConfig\n",
        "\n",
        "gen_cfg = GenerationConfig(\n",
        "    max_new_tokens=100,\n",
        "    do_sample=True,\n",
        "    temperature=1.2,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        ")\n",
        "outputs = model.generate(batch[\"input_ids\"], generation_config=gen_cfg)\n",
        "result = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "print(result[0])\n",
        "print(model.config.eos_token_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc2a90c5-637e-4b29-a6e2-c35f67e7a88a",
      "metadata": {
        "id": "fc2a90c5-637e-4b29-a6e2-c35f67e7a88a"
      },
      "source": [
        "# 5.4.3 Sequence Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8468e273-ebac-49c3-a0b4-cdd83bf00278",
      "metadata": {
        "id": "8468e273-ebac-49c3-a0b4-cdd83bf00278"
      },
      "source": [
        "### 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "74a6b0d3-6091-415b-b480-112d53141d5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74a6b0d3-6091-415b-b480-112d53141d5b",
        "outputId": "f8fbab14-3e2e-4634-9539-aaf6fea878ce",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at hyunwoongko/kobart and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BartForSequenceClassification(\n",
              "  (model): BartModel(\n",
              "    (shared): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartEncoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartDecoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (classification_head): BartClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"hyunwoongko/kobart\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0750323-05a8-41da-9f5c-054b14d13fce",
      "metadata": {
        "id": "b0750323-05a8-41da-9f5c-054b14d13fce",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### 데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "357747b3-1d25-450a-b35b-70305a288d06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "1a97ac9460854c95aaec47afae76ee9d",
            "879ab3bbf24641feadd64a86df2e80d3",
            "0889c5ee651842fe806072ef04809e61",
            "03fad7ecdc104334946af9774ebde985",
            "0741ac0189b44dff8c79f159c8674008",
            "ea084edba39b43eb8eb20512a43a16a0",
            "5a2cf877622a49bda66965ab132fa2e6",
            "c5491ee8e65c49f190fc9a82d0611b44",
            "24433cde54954cab9df626e7c0449b81",
            "c913f02194354e7488b2b1b455cc7b59",
            "79645117f9e044e5abdf9aa4694e8d81",
            "75dab9afe92a448da8797461058f51cb",
            "79f63665df3c4796b7a32acdc21c4b8e",
            "3ba5ea84750c4846a06961fe241218c3",
            "e1de9ec07cd44f0ab7d483f02149f482",
            "e37c07c03f2c433d911f05c9696eb524",
            "3abb7f61723249ba915b976b5007b305",
            "cc39857fba7443a28f7d6c5ee8bbc1dc",
            "95e0d0ced51c44a7be71288ed4824e01",
            "795786ac101b49368d82feebf48954cb",
            "1ec4d31562884bf3bc918359080ff03d",
            "e1f30aadbb1f4d6e8163580df6222e9d",
            "6788399ea22a4fe387a33e3d1f19f1eb",
            "ac0808d29f4a4378a1578155614895ee",
            "ea3acc7f8a83432494071c925b52ffbd",
            "8535d9b392c5495f90a6ac93b121f0b7",
            "02d5d6f6f29947298a7ebe4d641c0cb4",
            "229a3dbbb2304621a2487b2335e5d192",
            "a16c87d26cfc407d9ba2db808d2b8ede",
            "a7c30070e2eb42b69cb454293466e9e8",
            "e0f473b252924d23bef474d63f9d8257",
            "39ab24d41fbd46cfba298778bdd355ca",
            "a8cf692e29f6407781b39b9fee79739c",
            "589b372624514b7898f258e763ceff8a",
            "c1165ace456c4b0ba1c7de433137f290",
            "ae88e5e49dc74d0fa6936af6e79d0262",
            "72b5b067f3a6471286bd00de5f73ed0a",
            "c8c372ba8f6d4ef6b87663e29c955717",
            "3f38f05dc67a4792a3660fb42e3c399e",
            "d1205024ef97419d87278ada0df57a28",
            "52875c4107c64bbeb9d4bbacc61ea43a",
            "5be05e7bcf3e43f58dbd31ba892847f1",
            "ad0289aba5984eeb830b02f504bf92f9",
            "51a1f540a23f4c62a1f395ab52bc7daf",
            "4b2b6e63f2cd46b9b547bf51a75d95c2",
            "aea883f0ea284d2cb9c5b7cea9b6075b",
            "43e0b1826ebe4243a5a6752af795a52a",
            "ec1ca670676342b0a9ff57819cfc072a",
            "11ac3c6a98884b0a8a29eeaf01b37920",
            "4c5e9ea16c2e4df0a393a61582de403b",
            "e0994a9efdb54825b3b1a2f50b857698",
            "65f0483a22124e029a9458f74528341e",
            "978e91a2a65e4cdc884858db5499edcc",
            "c81f38d5ddec4ff785f3f6d49da224b7",
            "0039b9b33f1e44148b06ff3f7b074499",
            "0c27bb62626a465388b0198dc664388b",
            "30baa35de3d04e608e9fb28ffe0842b3",
            "246e8affe25a4030ac0d65a476eb6602",
            "9afaaeb8ff7945458b0fb7cc1b6bab92",
            "58cd390161b442048f62af3883620d07",
            "c95fa4906408435489a8520ea913aef3",
            "39b9d524d586414183c8c83361221346",
            "f1ddc775ae7f42b99520ec04cf3388c1",
            "f75856bc671e490d9fd4924144895abc",
            "86d7c04a8cc54254a4c56a14fa39d961",
            "1a2345b6b2d04c8da097a0aa29f0bd21",
            "4fc822bfde564878b1d497747f1ba45e",
            "1edfc1eddae54f0dbb2c43740a0beeb8",
            "050ef450866343a7b316641f2ddb90bd",
            "937c36bde82b49f7b8a4aa973a6dd33f",
            "cada9708f7ab402e82c34a3abe88996f",
            "87db1647e08f4d378728f17f0f0a9e9c",
            "5fbbceb4f7b240a9944c8ef37b58f419",
            "502502856c0f491d9aba8799532aae18",
            "467c79f1d1c14b11be50a58a190c4dee",
            "247410365fca4b8d8edaf63583b167f3",
            "62f5d146f29c4c8fac66cf05f24407aa"
          ]
        },
        "id": "357747b3-1d25-450a-b35b-70305a288d06",
        "outputId": "1bc4743a-13af-4314-84da-3d16a2d0fcd9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/22.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a97ac9460854c95aaec47afae76ee9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.52M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75dab9afe92a448da8797461058f51cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/68.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6788399ea22a4fe387a33e3d1f19f1eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/11668 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "589b372624514b7898f258e763ceff8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/519 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b2b6e63f2cd46b9b547bf51a75d95c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11668 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c27bb62626a465388b0198dc664388b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/519 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fc822bfde564878b1d497747f1ba45e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"klue\", \"sts\")\n",
        "\n",
        "def process_data(batch):\n",
        "  result = tokenizer(batch[\"sentence1\"], text_pair=batch[\"sentence2\"])\n",
        "  result[\"labels\"] = [x[\"binary-label\"] for x in batch[\"labels\"]]\n",
        "  return result\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    process_data,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_XYlNuWsPjSN",
      "metadata": {
        "id": "_XYlNuWsPjSN"
      },
      "source": [
        "### 문장 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2349fadd-a2b0-4006-8e36-1cd8da5a28b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2349fadd-a2b0-4006-8e36-1cd8da5a28b4",
        "outputId": "c5a955bf-2062-4188-c833-fce4f482086b",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1378,  0.4640],\n",
              "        [-0.2951,  0.5463],\n",
              "        [ 0.3902,  0.6520],\n",
              "        [-0.0374,  0.5470]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "collator = DataCollatorWithPadding(tokenizer)\n",
        "batch = collator([tokenized_dataset[\"train\"][i] for i in range(4)])\n",
        "\n",
        "with torch.no_grad():\n",
        "  logits = model(**batch).logits\n",
        "\n",
        "logits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d98db25-4353-4542-9197-fae34992b0fc",
      "metadata": {
        "id": "9d98db25-4353-4542-9197-fae34992b0fc"
      },
      "source": [
        "### 평가 지표"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bec3e24f-a67e-4a7f-9186-2ebfb3b4e2bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "2ee01121e51348b8a6dc64af8cb617f4",
            "b1335094ba354f27b25ef5812686f9ad",
            "f6ad8f33b5764c42a21b3b05df8c57b7",
            "37f269b815ef431a8ec89e2b0f2a1f91",
            "9f88e68e7aa24018967eabadcbe3b01b",
            "090484655b604590ab7c193142ed7e0f",
            "63e0f1adb0cc47bd9c2118245d8ffb90",
            "62aecc3e6cce40bc98e9a8506c91da96",
            "32abe5cbd54849c1b04a69e0b9a55c85",
            "6a4dfd84cc004fae8af7eaef74389cb2",
            "169997168aae41ca85d33a9523c8bb58"
          ]
        },
        "id": "bec3e24f-a67e-4a7f-9186-2ebfb3b4e2bb",
        "outputId": "0355a5a4-fa5a-4809-9995-02ec072db746"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ee01121e51348b8a6dc64af8cb617f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 0.25}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "f1 = evaluate.load(\"f1\")\n",
        "f1.compute(\n",
        "    predictions=logits.argmax(-1),\n",
        "    references=batch[\"labels\"],\n",
        "    average=\"micro\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hUrAaiAnPvoS",
      "metadata": {
        "id": "hUrAaiAnPvoS"
      },
      "source": [
        "# 5.4.4 Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-KUIhSZRPzhe",
      "metadata": {
        "id": "-KUIhSZRPzhe"
      },
      "source": [
        "### 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "PHwhRPDgPyoG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHwhRPDgPyoG",
        "outputId": "1762bcf5-15bb-4621-b173-9ddfb6d64174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Some weights of BartForQuestionAnswering were not initialized from the model checkpoint at hyunwoongko/kobart and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BartForQuestionAnswering(\n",
              "  (model): BartModel(\n",
              "    (shared): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartEncoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartDecoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "model_name = \"hyunwoongko/kobart\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9sUxjrBrQHEw",
      "metadata": {
        "id": "9sUxjrBrQHEw"
      },
      "source": [
        "### 데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "cVbUl9_2P7f_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "c8b0fd3f548149788d9fe072706a8483",
            "2b24006dcd0e45fba9a16f2e425cd746",
            "d536721d5e254b50bc7dd13e5c243f82",
            "fe338454ea57475398ae281f8a946994",
            "0ce2c03a5059489f85eb4acec9eed795",
            "b0776d4ffa8645e5b3bd0582f421de92",
            "4ca47e1a8d274713959898c4a495b263",
            "7751d4a8d12c41e494c46599451668e2",
            "44ebdc4922754c6c9ac8aa3067ceeb3f",
            "12f930c757ce45c3afdf8117f349f8c8",
            "36409dd491ee40828bddb6b45814d5d6",
            "abe7ce58dfc5430787bde6a7e2e3b34a",
            "28341db06e7d4754a4797a8d444a623b",
            "849298c49bfc47dc866dc93154040da3",
            "177695c3622c445c8e6778e8667e7396",
            "24b5235d5dc5462ea7744e42bea37a4d",
            "c0d70f914f6149a996376f8cace52a08",
            "48b0c71dc95f4534b9112c8fd0ed43ac",
            "6327b7b0ef6a47728c8a582e33ab9c9a",
            "7d050beaa57d4fa19090649ead410f35",
            "77ceabf9c4f541529428afdf5d22fe33",
            "d3710e82bc344f9eb097dca6f7a4f297",
            "6b464de0f8ab4e40b35b1ef281e26844",
            "b168ac40ea66494393742c576ff61eb7",
            "675257b633a847d7a12a8d8e20f95329",
            "03d5363ab59946249911d45ddfa4bddd",
            "1c7572e66961470b8812564990928ede",
            "7f5b2a93f3514fc99bd4a88878a5c51c",
            "43d511798c66452ab90c5fdb5d2cea22",
            "c371656dee7f4e07b11a57494ad4fb1c",
            "ddc11dd25fb84cd684810bf94d06aeeb",
            "2bb4f8a9eb364b179e4c274e5f27b00e",
            "9d5adf9c08304cf094fd27e46d479bf3",
            "7550d4559a72407aae5b6f2b75892dea",
            "6986ee3f67f14dc8a13d20ca442c8295",
            "e255380bb75c4ed3a421ee2ab30b0376",
            "3a184347a0114431b7b2fea0f0fb9879",
            "ea6d6e56e25944f98e9187eee45a53dc",
            "3fe1e6b8935840ff84a98e42bfcd4fb4",
            "4b978bcf5c454c8fb6802b727eb1b7d0",
            "5dba23f7dcd64bd39ba5380613cafe64",
            "423d71c2064140a9a11a474b2d1b0d0e",
            "e8c64cfe286a463192bb9541a2fe453b",
            "06658c6950cf48d69d2d57656705e65b",
            "ef8b61af38bf4a2fbb2c4e8c5121cc29",
            "fd5c6923487849088d1bfd2088f604ad",
            "e157168b41e94f49a3cfad549fd2a096",
            "4113b2b45d0f47148b0fc957e0092873",
            "c2401ca4811c4d23a5f24ec1bc20fd91",
            "8228d878cc5c49b1b7ff176b06189be1",
            "45a93a7129594310aac571b66363886f",
            "377f7b6c567d472096a52f2c33a33983",
            "2578797aef964d15ae51a8d23d9b843f",
            "db51621a1cae43d6b6fe6b4f13cc69db",
            "3f4de56b0fcf4f29935052efe16c64b9",
            "955730b21fc74353b520cf3b64fea59e",
            "e7f93beac7ef49708f4b3feb77adaffd",
            "6d64807cde4a412cab49b10d96629293",
            "101dad1fccfb4989a2e6a9f0f25d45ef",
            "eac305a98d8d4c139b7d7f9d45f9f422",
            "58470025c5c749daa6958ba213d2ffb4",
            "ae6f399da177415eb160c1ce91ea7b4c",
            "27657b787b34451d95ff1d802256b7c5",
            "9b2e641baf064d2b8141b15148d753a3",
            "7a769da047384a7e8adcf73bb0d7e757",
            "22c718c4620d441282bf42810ad0c556"
          ]
        },
        "id": "cVbUl9_2P7f_",
        "outputId": "b02f52cd-c281-4e35-a872-694ae5be3bb4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8b0fd3f548149788d9fe072706a8483"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abe7ce58dfc5430787bde6a7e2e3b34a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/17554 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b464de0f8ab4e40b35b1ef281e26844"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/5841 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7550d4559a72407aae5b6f2b75892dea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/17554 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef8b61af38bf4a2fbb2c4e8c5121cc29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5841 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "955730b21fc74353b520cf3b64fea59e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"klue\", \"mrc\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=512,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "          idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "          idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wx2ne0BXQOgz",
      "metadata": {
        "id": "wx2ne0BXQOgz"
      },
      "source": [
        "### 문장 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "56sZseR3QJEl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56sZseR3QJEl",
        "outputId": "e1a68e7d-71e9-441a-aace-ad2ae6f50def"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    0, 14337, 26225,  ...,     3,     3,     3],\n",
              "         [    0, 25092, 18001,  ..., 11270, 19903,     1],\n",
              "         [    0, 25788, 13679,  ..., 19903, 15599,     1],\n",
              "         ...,\n",
              "         [    0, 20437, 17814,  ...,     3,     3,     3],\n",
              "         [    0, 14154, 12061,  ...,     3,     3,     3],\n",
              "         [    0, 14295, 14120,  ...,     3,     3,     3]]),\n",
              " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " 'start_positions': tensor([233,  27,   0,  78,  60,  68, 202, 319, 306, 271]),\n",
              " 'end_positions': tensor([235,  29,   0,  79,  66,  74, 210, 325, 312, 275])}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()\n",
        "batch = data_collator([tokenized_dataset[\"train\"][i] for i in range(10)])\n",
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "SEsGxdFUQVck",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SEsGxdFUQVck",
        "outputId": "17f2e72a-2539-41cf-b114-110f368f7e27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs = model(**batch)\n",
        "\n",
        "answer_start_index = outputs.start_logits.argmax()\n",
        "answer_end_index = outputs.end_logits.argmax()\n",
        "\n",
        "predict_answer_tokens = batch[\"input_ids\"][0, answer_start_index : answer_end_index + 1]\n",
        "tokenizer.decode(predict_answer_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "P5J74806akVZ",
      "metadata": {
        "id": "P5J74806akVZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
 
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
